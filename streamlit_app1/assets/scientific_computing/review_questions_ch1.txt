REVIEW QUESTIONS
1.1 True or false: A problem is ill-conditioned if its solution is highly sensitive to small changes in the problem data.
1.2 True or false: Using higher-precision arithmetic will make an ill-conditioned problem better conditioned.
1.3 True or false: The conditioning of a problem depends on the algorithm used to solve it.
1.4 True or false: A good algorithm will produce an accurate solution regardless of the condition of the problem being solved.
1.5 True or false: The choice of algorithm for solving a problem has no effect on the propagated data error.
1.6 True or false: If two real numbers are exactly representable as floating-point numbers, then the result of a real arithmetic operation on them will also be representable as a floatingpoint number.
1.7 True or false: Floating-point numbers are distributed uniformly throughout their range.
1.8 True or false: Floating-point addition is associative but not commutative.
1.9 True or false: In a floating-point number system, the underflow level is the smallest positive number that perturbs the number 1 when added to it.
1.10 Explain the distinction between truncation (or discretization) and rounding.
1.11 Explain the distinction between absolute error and relative error.
1.12 Explain the distinction between computational error and propagated data error.
1.13 (a) What is meant by the conditioning of a problem?
(b) Is it affected by the algorithm used to solve the problem?
(c) Is it affected by the precision of the arithmetic used to solve the problem?
1.14 If a computational problem has a condition number of 1, is this good or bad? Why?
1.15 When is an approximate solution to a given problem considered to be good according to backward error analysis?
1.16 For a given floating-point number sys-tem, describe in words the distribution of machine numbers along the real line.
1.17 In floating-point arithmetic, which is generally more harmful, underflow or overflow? Why?
1.18 Infloating-pointarithmetic,whichofthe following operations on two positive floatingpoint operands can produce an overflow?
(a) Addition (b) Subtraction (c) Multiplication (d) Division
1.19 Infloating-pointarithmetic,whichofthe following operations on two positive floatingpoint operands can produce an underflow?
(a) Addition (b) Subtraction (c) Multiplication (d) Division
1.20 List of reasons  why floating-point number systems are usually normalized.
1.21 In a floating-point system, what quantity determines the maximum relative error in representing a given real number by a machine number?
1.22 (a) Explain the difference between the rounding rules “round toward zero” and “round to nearest” in a floating-point system.
(b) Which of these two rounding rules is more accurate?
(c) What quantitative difference does this make in the unit roundoff εmach?
1.23 In a t-digit binary floating-point system with rounding to nearest, what is the value of the unit roundoff $\epsilon_\text{mach}$?
1.24 In a floating-point system with gradual underflow (subnormal numbers), is the representation of each number still unique? Why?
1.25 Inafloating-pointsystem,istheproduct of two machine numbers usually exactly representable in the floating-point system? Why?
1.26 In a floating-point system, is the quotient of two nonzero machine numbers always exactly representable in the floating-point system? Why?
1.27 (a) Give an example to show that floating-point addition is not necessarily associative.
(b) Give an example to show that floatingpoint multiplication is not necessarily associative.
1.28 Give an example of a number whose decimal representation is finite (i.e., it has only a finite number of nonzero digits) but whose binary representation is not.
1.29 Give examples of floating-point arithmetic operations that would produce each of the exceptional values Inf and NaN.
1.30 Explainwhythecancellationthatoccurs when two numbers of similar magnitude are subtracted is often bad even though the result may be exactly correct for the actual operands involved.
1.31 Assume a decimal (base 10) floatingpoint system having machine precision $\epsilon_\text{mach} = 10^{−5}$ and an exponent range of $\pm20$. What is the result of each of the following floating-point arithmetic operations?
(a) $1 + 10^{−7}$
(b) $1 + 10^3$
(c) $1+10^7$
(d) $10^{10} + 10^3$
(e) $10^{10}/10^{−15}$
(f) $10^{−10} \times 10^{−15}$
1.32 In a floating-point number system having an underflow level of $\text{UFL} = 10^{−38}$, which of the following computations will incur an underflow?
1.33 (a) Explain in words the difference between the unit roundoff, εmach, and the underflow level, UFL, in a floating-point system.
Of these two quantities,
(b) Which one depends only on the number of digits in the mantissa field?
(c) Which one depends only on the number of digits in the exponent field?
(d) Which one does not depend on the rounding rule used?
(e) Which one is not affected by allowing subnormal numbers?
1.34 Let xk be a monotonically decreasing, finite sequence of positive numbers (i.e., xk > xk+1 for each k). Assuming it is practical to take the numbers in any order we choose, in what order should the sequence be summed to minimize rounding error?
1.35 Is cancellation an example of rounding error? Why?
1.36 (a) Explain why a divergent infinite series, such as $$\sum_{n=1}^\infty\frac{1}{n},$
can have a finite sum in floating-point arithmetic.
(b) At what point will the partial sums cease to change?
1.37 In floating-point arithmetic, if you are computing the sum of a convergent infinite se-
(a) a = √b2 + c2, with b = 1, c = 10−25. √
(b)a= b2+c2,withb=c=10−25.
(c) u = (v×w)/(y×z), with v = 10−15,
of positive terms in the natural order, what stopping criterion would you use to attain the maximum possible accuracy using the smallest number of terms?
1.38 Explain why an alternating infinite series, such as
x x2x3
e =1+x+2!+3!+···
for x < 0, is difficult to evaluate accurately in floating-point arithmetic.
1.39 If f is a real-valued function of a real variable, the truncation error of the finite difference approximation to the derivative
f′(x)≈ f(x+h)−f(x) h
goes to zero as h → 0. If we use floatingpoint arithmetic, list two factors that limit how small a value of h we can use in practice.
1.40 For computing the midpoint m of an interval [x, y], which of the following two formulas is preferable in floating-point arithmetic? Why?
(a) m = (x + y)/2.0
(b) m = x + (y − x)/2.0
1.41 List at least two ways in which evaluation of the quadratic formula
−b±√b2 −4ac x= 2a
may suffer numerical difficulties in floatingpoint arithmetic.
over a large population and then rounding to three significant digits. In fact, however, 98.6 is simply the Fahrenheit equivalent of 37 degrees Celsius, which is accurate to only two
w = 10−30, y = 10−20, and z = 10−25.
In each case where underflow occurs, is it reasonable simply to set to zero the quantity that underflows?
